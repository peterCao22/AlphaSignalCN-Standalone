# å¸‚åœºçƒ­ç‚¹ä¸èµšé’±æ•ˆåº”æ•°æ®é›†æˆæ–¹æ¡ˆ

## èƒŒæ™¯
002202 æ¡ˆä¾‹è¯æ˜ï¼šå½“å‰æ¨¡å‹ç¼ºå°‘**å¸‚åœºæƒ…ç»ªå’Œçƒ­ç‚¹æ•ˆåº”**ç»´åº¦ï¼Œå¯¼è‡´å¯¹å¼ºåŠ¿è‚¡çš„è¯†åˆ«èƒ½åŠ›ä¸è¶³ã€‚

ç”¨æˆ·æå‡ºçš„ä¸¤ä¸ªæ•°æ®æºå®Œç¾è§£å†³è¿™ä¸ªé—®é¢˜ï¼š
1. **åŒèŠ±é¡ºå¸‚åœºçƒ­ç‚¹**ï¼šæ¿å—è½®åŠ¨ã€æ¦‚å¿µç‚’ä½œ
2. **ä¹å’•ä¹è‚¡èµšé’±æ•ˆåº”**ï¼šå¸‚åœºæƒ…ç»ªé‡åŒ–æŒ‡æ ‡

## æ•°æ®ä»·å€¼åˆ†æ

### 1ï¸âƒ£ åŒèŠ±é¡ºå¸‚åœºçƒ­ç‚¹
**æ•°æ®æº**ï¼šhttps://eq.10jqka.com.cn/frontend/thsTopRank/index.html#/ ï¼ˆæ¿å—æ ‡ç­¾ï¼‰

#### å¯è·å–æ•°æ®
- **çƒ­é—¨æ¿å—æ’å**ï¼šæ¶¨å¹…å‰åˆ—çš„è¡Œä¸š/æ¦‚å¿µæ¿å—
- **æ¿å—æ¶¨è·Œå¹…**ï¼šåæ˜ æ¿å—å¼ºåº¦
- **æ¿å—å†…ä¸ªè‚¡æ•°é‡**ï¼šæ¿å—è§„æ¨¡
- **é¢†æ¶¨è‚¡**ï¼šæ¿å—é¾™å¤´
- **æ¿å—èµ„é‡‘æµå‘**ï¼šä¸»åŠ›èµ„é‡‘å‡€æµå…¥

#### ç‰¹å¾å·¥ç¨‹è®¾è®¡
```python
# æ–°å¢ç‰¹å¾ - æ¿å—æ•ˆåº”
'is_hot_sector': bool,              # æ˜¯å¦å±äºçƒ­é—¨æ¿å—ï¼ˆTOP10ï¼‰
'sector_rank': int,                  # æ¿å—æ’å
'sector_gain': float,                # æ‰€å±æ¿å—æ¶¨å¹…
'sector_leader_gain': float,         # æ¿å—é¾™å¤´æ¶¨å¹…
'sector_capital_inflow': float,      # æ¿å—èµ„é‡‘æµå…¥
'sector_stock_count': int,           # æ¿å—ä¸ªè‚¡æ•°é‡
'is_sector_leader': bool,            # æ˜¯å¦ä¸ºæ¿å—é¾™å¤´
'sector_position_rank': int,         # åœ¨æ¿å—å†…çš„æ¶¨å¹…æ’å
```

#### å¯¹ 002202 çš„å½±å“
å‡è®¾ 002202 åœ¨ 2025-12-29 å±äºæŸçƒ­é—¨æ¦‚å¿µï¼ˆå¦‚"AIåº”ç”¨"ï¼‰ï¼š
- æ¿å—æ’åï¼šTOP3
- æ¿å—æ¶¨å¹…ï¼š+5.2%
- æ¿å—èµ„é‡‘æµå…¥ï¼š20äº¿

**æ¨¡å‹è°ƒæ•´**ï¼š
```python
# çƒ­é—¨æ¿å—åŠ æˆ
if is_hot_sector and sector_rank <= 10:
    strength += 25  # çƒ­ç‚¹åŠ æˆ
    
if is_sector_leader:
    strength += 15  # é¾™å¤´åŠ æˆ
    
# æ¿å—èµ„é‡‘ä¸ä¸ªè‚¡èµ„é‡‘å…±æŒ¯
if sector_capital_inflow > 1e9 and net_buy > 1e8:  # 10äº¿æ¿å—èµ„é‡‘ + 1äº¿ä¸ªè‚¡èµ„é‡‘
    strength += 30  # å¼ºåŠ¿å…±æŒ¯
```

**é¢„æœŸæ•ˆæœ**ï¼š002202 çš„é¢„æµ‹æ¦‚ç‡å¯èƒ½ä» 0.40 æå‡è‡³ 0.65+

---

### 2ï¸âƒ£ ä¹å’•ä¹è‚¡èµšé’±æ•ˆåº”
**æ•°æ®æº**ï¼šhttps://www.legulegu.com/stockdata/market-activity

#### å¯è·å–æ•°æ®
```python
# å®æ—¶æ•°æ®ï¼ˆ2026-01-09 15:00:00ï¼‰
{
    'market_activity': 71.73,           # æ´»è·ƒåº¦ï¼ˆæ¶¨è·Œæ¯”ï¼‰
    'up_count': 3718,                   # ä¸Šæ¶¨ä¸ªè‚¡æ•°
    'down_count': 1272,                 # ä¸‹è·Œä¸ªè‚¡æ•°
    'limit_up_count': 111,              # æ¶¨åœä¸ªè‚¡æ•°
    'limit_up_real_count': 92,          # çœŸå®æ¶¨åœæ•°ï¼ˆéä¸€å­—æ¿ï¼‰
    'limit_down_count': 3,              # è·Œåœä¸ªè‚¡æ•°
    'median_gain': {                    # ä¸­ä½æ•°æ¶¨å¹…
        'all': 0.68,
        'hs300': 0.26,
        'sh': 0.62,
        'sz': 0.76,
        'cyb': 0.62
    }
}
```

#### ç‰¹å¾å·¥ç¨‹è®¾è®¡
```python
# æ–°å¢ç‰¹å¾ - å¸‚åœºæƒ…ç»ª
'market_activity': float,            # å¸‚åœºæ´»è·ƒåº¦ï¼ˆæ¶¨è·Œæ¯”ï¼‰
'market_limit_up_count': int,        # å…¨å¸‚åœºæ¶¨åœå®¶æ•°
'market_limit_up_real': int,         # çœŸå®æ¶¨åœå®¶æ•°
'market_median_gain': float,         # å…¨å¸‚åœºä¸­ä½æ•°æ¶¨å¹…
'market_sentiment_score': float,     # ç»¼åˆæƒ…ç»ªå¾—åˆ†ï¼ˆè‡ªå®šä¹‰ï¼‰

# ç›¸å¯¹å¼ºåº¦ç‰¹å¾
'relative_strength_to_market': float, # ä¸ªè‚¡æ¶¨å¹… / å¸‚åœºä¸­ä½æ•°æ¶¨å¹…
'limit_up_premium': float,            # æ¶¨åœæº¢ä»·ï¼ˆå½“æ—¥æ¶¨åœæ•° / å†å²å‡å€¼ï¼‰
```

#### æƒ…ç»ªå¾—åˆ†è®¡ç®—
```python
def calculate_market_sentiment_score(data):
    """
    è®¡ç®—å¸‚åœºç»¼åˆæƒ…ç»ªå¾—åˆ†ï¼ˆ0-100ï¼‰
    
    é€»è¾‘ï¼š
    - æ¶¨è·Œæ¯” > 70%ï¼šå¼ºåŠ¿å¸‚åœºï¼ˆ+30åˆ†ï¼‰
    - çœŸå®æ¶¨åœæ•° > 80ï¼šæŠ•æœºæ°›å›´æµ“åšï¼ˆ+25åˆ†ï¼‰
    - ä¸­ä½æ•°æ¶¨å¹… > 0.5%ï¼šæ™®æ¶¨è¡Œæƒ…ï¼ˆ+20åˆ†ï¼‰
    - è·Œåœæ•° < 5ï¼šé£é™©å¯æ§ï¼ˆ+15åˆ†ï¼‰
    - æ´»è·ƒåº¦è¶‹åŠ¿ï¼šä¸Šå‡ï¼ˆ+10åˆ†ï¼‰
    """
    score = 0
    
    # æ¶¨è·Œæ¯”åŠ åˆ†
    if data['market_activity'] > 70:
        score += 30
    elif data['market_activity'] > 60:
        score += 20
    elif data['market_activity'] > 50:
        score += 10
    
    # æ¶¨åœå®¶æ•°åŠ åˆ†
    if data['limit_up_real_count'] > 80:
        score += 25
    elif data['limit_up_real_count'] > 50:
        score += 15
    elif data['limit_up_real_count'] > 30:
        score += 10
    
    # ä¸­ä½æ•°æ¶¨å¹…åŠ åˆ†
    if data['median_gain']['all'] > 0.5:
        score += 20
    elif data['median_gain']['all'] > 0.3:
        score += 10
    
    # è·Œåœæ•°æ‰£åˆ†
    if data['limit_down_count'] > 10:
        score -= 15
    elif data['limit_down_count'] < 5:
        score += 15
    
    return min(max(score, 0), 100)  # é™åˆ¶åœ¨0-100
```

#### å¯¹ 002202 çš„å½±å“
å‡è®¾ 2025-12-29 çš„å¸‚åœºæƒ…ç»ªæ•°æ®ï¼š
- æ¶¨è·Œæ¯”ï¼š73%ï¼ˆå¼ºåŠ¿å¸‚åœºï¼‰
- çœŸå®æ¶¨åœï¼š95ä¸ªï¼ˆé«˜æŠ•æœºæ°›å›´ï¼‰
- ä¸­ä½æ•°æ¶¨å¹…ï¼š0.72%ï¼ˆæ™®æ¶¨ï¼‰
- æƒ…ç»ªå¾—åˆ†ï¼š75åˆ†ï¼ˆé«˜æƒ…ç»ªï¼‰

**æ¨¡å‹è°ƒæ•´**ï¼š
```python
# å¸‚åœºæƒ…ç»ªåŠ æˆ
if market_sentiment_score > 70:
    strength += 20  # å¼ºåŠ¿å¸‚åœºåŠ©æ¨
    final_prob *= 1.15  # æ¦‚ç‡ä¸Šæµ®15%
    
# ç›¸å¯¹å¼ºåº¦åˆ¤æ–­
if relative_strength_to_market > 3.0:  # ä¸ªè‚¡æ¶¨å¹…æ˜¯å¸‚åœºä¸­ä½æ•°çš„3å€
    strength += 20  # æ˜æ˜¾è·‘èµ¢å¤§ç›˜
```

**é¢„æœŸæ•ˆæœ**ï¼šè¿›ä¸€æ­¥æå‡é¢„æµ‹å‡†ç¡®ç‡

---

## æŠ€æœ¯å®ç°æ–¹æ¡ˆ

### Phase 1: æ•°æ®çˆ¬å–ï¼ˆ1-2å¤©ï¼‰

#### 1.1 åŒèŠ±é¡ºçƒ­é—¨æ¿å—çˆ¬è™«
```python
# stockainews/crawlers/tonghuashun/hot_sectors.py

import asyncio
from playwright.async_api import async_playwright
from typing import List, Dict, Any
from stockainews.core.logger import setup_logger

logger = setup_logger(__name__)

class TonghuashunHotSectorsCrawler:
    """åŒèŠ±é¡ºçƒ­é—¨æ¿å—çˆ¬è™«"""
    
    BASE_URL = "https://eq.10jqka.com.cn/frontend/thsTopRank/index.html#/"
    
    async def crawl_hot_sectors(self) -> List[Dict[str, Any]]:
        """
        çˆ¬å–çƒ­é—¨æ¿å—æ•°æ®
        
        Returns:
            [
                {
                    'rank': 1,
                    'sector_name': 'AIåº”ç”¨',
                    'sector_gain': 5.23,
                    'leader_stock': '002202',
                    'leader_gain': 10.01,
                    'stock_count': 85,
                    'capital_inflow': 2000000000,  # 20äº¿
                    'crawl_time': '2025-12-29 15:00:00'
                },
                ...
            ]
        """
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                # è®¿é—®é¡µé¢
                await page.goto(self.BASE_URL, wait_until="networkidle")
                
                # ç‚¹å‡»"æ¿å—"æ ‡ç­¾
                await page.click('text=æ¿å—')
                await asyncio.sleep(2)
                
                # æå–æ¿å—æ•°æ®ï¼ˆéœ€è¦æ ¹æ®å®é™…DOMç»“æ„è°ƒæ•´ï¼‰
                sectors = await page.evaluate('''
                    () => {
                        const rows = document.querySelectorAll('.sector-table tbody tr');
                        return Array.from(rows).slice(0, 20).map((row, index) => {
                            const cells = row.querySelectorAll('td');
                            return {
                                rank: index + 1,
                                sector_name: cells[1]?.innerText || '',
                                sector_gain: parseFloat(cells[2]?.innerText) || 0,
                                leader_stock: cells[3]?.innerText || '',
                                leader_gain: parseFloat(cells[4]?.innerText) || 0,
                                stock_count: parseInt(cells[5]?.innerText) || 0,
                                capital_inflow: parseFloat(cells[6]?.innerText) * 1e8 || 0
                            };
                        });
                    }
                ''')
                
                logger.info(f"æˆåŠŸçˆ¬å– {len(sectors)} ä¸ªçƒ­é—¨æ¿å—")
                return sectors
                
            except Exception as e:
                logger.error(f"çˆ¬å–çƒ­é—¨æ¿å—å¤±è´¥: {e}", exc_info=True)
                return []
            finally:
                await browser.close()

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    crawler = TonghuashunHotSectorsCrawler()
    sectors = await crawler.crawl_hot_sectors()
    print(sectors)

if __name__ == "__main__":
    asyncio.run(main())
```

#### 1.2 ä¹å’•ä¹è‚¡èµšé’±æ•ˆåº”çˆ¬è™«
```python
# stockainews/crawlers/legulegu/market_activity.py

import httpx
from typing import Dict, Any
from datetime import datetime
from stockainews.core.logger import setup_logger

logger = setup_logger(__name__)

class LeguLeguMarketActivityCrawler:
    """ä¹å’•ä¹è‚¡èµšé’±æ•ˆåº”çˆ¬è™«"""
    
    BASE_URL = "https://www.legulegu.com/stockdata/market-activity"
    
    def crawl_market_activity(self) -> Dict[str, Any]:
        """
        çˆ¬å–èµšé’±æ•ˆåº”æ•°æ®
        
        Returns:
            {
                'market_activity': 71.73,
                'up_count': 3718,
                'down_count': 1272,
                'limit_up_count': 111,
                'limit_up_real_count': 92,
                'limit_down_count': 3,
                'median_gain': {
                    'all': 0.68,
                    'hs300': 0.26,
                    'sh': 0.62,
                    'sz': 0.76,
                    'cyb': 0.62
                },
                'crawl_time': '2026-01-09 15:00:00'
            }
        """
        try:
            # å°è¯•APIæ¥å£ï¼ˆå¦‚æœæœ‰ï¼‰
            # å¦‚æœæ²¡æœ‰APIï¼Œä½¿ç”¨Playwrightçˆ¬å–HTML
            
            # è¿™é‡Œå‡è®¾ä½¿ç”¨httpxç›´æ¥è¯·æ±‚ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
            response = httpx.get(self.BASE_URL, timeout=30)
            
            if response.status_code != 200:
                logger.error(f"è¯·æ±‚å¤±è´¥: {response.status_code}")
                return {}
            
            # è§£æHTMLï¼ˆä½¿ç”¨BeautifulSoupæˆ–æ­£åˆ™ï¼‰
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æå–æ•°æ®ï¼ˆéœ€è¦æ ¹æ®å®é™…DOMç»“æ„è°ƒæ•´ï¼‰
            data = {
                'market_activity': self._extract_activity(soup),
                'up_count': self._extract_up_count(soup),
                'down_count': self._extract_down_count(soup),
                'limit_up_count': self._extract_limit_up_count(soup),
                'limit_up_real_count': self._extract_limit_up_real(soup),
                'limit_down_count': self._extract_limit_down_count(soup),
                'median_gain': self._extract_median_gain(soup),
                'crawl_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            logger.info(f"æˆåŠŸçˆ¬å–èµšé’±æ•ˆåº”æ•°æ®: æ´»è·ƒåº¦={data['market_activity']:.2f}%")
            return data
            
        except Exception as e:
            logger.error(f"çˆ¬å–èµšé’±æ•ˆåº”æ•°æ®å¤±è´¥: {e}", exc_info=True)
            return {}
    
    def _extract_activity(self, soup) -> float:
        """æå–æ¶¨è·Œæ¯”"""
        # æ ¹æ®å®é™…DOMç»“æ„å®ç°
        pass
    
    def _extract_up_count(self, soup) -> int:
        """æå–ä¸Šæ¶¨ä¸ªè‚¡æ•°"""
        pass
    
    # ... å…¶ä»–æå–æ–¹æ³•
```

### Phase 2: æ•°æ®å­˜å‚¨ï¼ˆ1å¤©ï¼‰

#### 2.1 æ•°æ®åº“è®¾è®¡
```sql
-- çƒ­é—¨æ¿å—æ•°æ®è¡¨
CREATE TABLE hot_sectors (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    crawl_date DATE NOT NULL,
    rank INTEGER NOT NULL,
    sector_name VARCHAR(50) NOT NULL,
    sector_gain REAL,
    leader_stock VARCHAR(10),
    leader_gain REAL,
    stock_count INTEGER,
    capital_inflow REAL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å¸‚åœºæƒ…ç»ªæ•°æ®è¡¨
CREATE TABLE market_sentiment (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    crawl_date DATE NOT NULL,
    market_activity REAL,
    up_count INTEGER,
    down_count INTEGER,
    limit_up_count INTEGER,
    limit_up_real_count INTEGER,
    limit_down_count INTEGER,
    median_gain_all REAL,
    median_gain_hs300 REAL,
    median_gain_sh REAL,
    median_gain_sz REAL,
    median_gain_cyb REAL,
    sentiment_score REAL,  -- è‡ªå®šä¹‰æƒ…ç»ªå¾—åˆ†
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(crawl_date)  -- æ¯æ—¥ä¸€æ¡è®°å½•
);
```

#### 2.2 æ•°æ®æœåŠ¡
```python
# stockainews/services/market_sentiment_service.py

from typing import Dict, Any, Optional
from datetime import datetime, date
import sqlite3
from pathlib import Path

class MarketSentimentService:
    """å¸‚åœºæƒ…ç»ªæ•°æ®æœåŠ¡"""
    
    def __init__(self, db_path: str = "data/market_sentiment.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_db()
    
    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºè¡¨ï¼ˆSQLè§ä¸Šï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS hot_sectors (...)
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS market_sentiment (...)
        ''')
        
        conn.commit()
        conn.close()
    
    def save_hot_sectors(self, sectors: list):
        """ä¿å­˜çƒ­é—¨æ¿å—æ•°æ®"""
        pass
    
    def save_market_sentiment(self, data: dict):
        """ä¿å­˜å¸‚åœºæƒ…ç»ªæ•°æ®"""
        pass
    
    def get_stock_sector_info(self, stock_code: str, trade_date: date) -> Dict[str, Any]:
        """
        è·å–è‚¡ç¥¨çš„æ¿å—ä¿¡æ¯
        
        Returns:
            {
                'is_hot_sector': True,
                'sector_rank': 3,
                'sector_name': 'AIåº”ç”¨',
                'sector_gain': 5.23,
                'is_sector_leader': False,
                'sector_position_rank': 5
            }
        """
        pass
    
    def get_market_sentiment(self, trade_date: date) -> Dict[str, Any]:
        """
        è·å–å¸‚åœºæƒ…ç»ªæ•°æ®
        
        Returns:
            {
                'market_activity': 71.73,
                'limit_up_real_count': 92,
                'sentiment_score': 75.0,
                ...
            }
        """
        pass
```

### Phase 3: ç‰¹å¾é›†æˆï¼ˆ2å¤©ï¼‰

#### 3.1 æ‰©å±• PatternMatcher
```python
# pattern_matcher.py ä¿®æ”¹

def get_stock_features(self, symbol, date):
    """æå–æŒ‡å®šè‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸçš„ç‰¹å¾"""
    # ... åŸæœ‰ç‰¹å¾æå–ä»£ç  ...
    
    # ã€æ–°å¢ã€‘æ¿å—æ•ˆåº”ç‰¹å¾
    from stockainews.services.market_sentiment_service import MarketSentimentService
    sentiment_service = MarketSentimentService()
    
    sector_info = sentiment_service.get_stock_sector_info(
        stock_code=symbol.split('.')[0],
        trade_date=date.date()
    )
    
    # ã€æ–°å¢ã€‘å¸‚åœºæƒ…ç»ªç‰¹å¾
    market_data = sentiment_service.get_market_sentiment(date.date())
    
    # åˆå¹¶ç‰¹å¾
    features.update({
        # æ¿å—ç‰¹å¾
        'is_hot_sector': sector_info.get('is_hot_sector', False),
        'sector_rank': sector_info.get('sector_rank', 999),
        'sector_gain': sector_info.get('sector_gain', 0),
        'is_sector_leader': sector_info.get('is_sector_leader', False),
        
        # å¸‚åœºæƒ…ç»ªç‰¹å¾
        'market_activity': market_data.get('market_activity', 50),
        'market_limit_up_real': market_data.get('limit_up_real_count', 0),
        'market_sentiment_score': market_data.get('sentiment_score', 50),
        'relative_strength': pct_change / market_data.get('median_gain_all', 1) if market_data.get('median_gain_all', 0) != 0 else 0
    })
    
    return features
```

#### 3.2 ä¼˜åŒ–è¯„åˆ†é€»è¾‘
```python
# pattern_matcher.py calculate_scores() ä¿®æ”¹

def calculate_scores(self, features, similar_cases):
    """è®¡ç®—å¼ºåº¦åˆ†å’Œæ¨¡å¼åˆ†"""
    # ... åŸæœ‰è®¡ç®—é€»è¾‘ ...
    
    # ã€æ–°å¢ã€‘æ¿å—æ•ˆåº”åŠ æˆ
    if features.get('is_hot_sector', False):
        if features.get('sector_rank', 999) <= 5:
            strength += 30  # TOP5çƒ­é—¨æ¿å—
        elif features.get('sector_rank', 999) <= 10:
            strength += 20  # TOP10çƒ­é—¨æ¿å—
        
        if features.get('is_sector_leader', False):
            strength += 15  # æ¿å—é¾™å¤´
    
    # ã€æ–°å¢ã€‘å¸‚åœºæƒ…ç»ªåŠ æˆ
    sentiment_score = features.get('market_sentiment_score', 50)
    if sentiment_score > 70:
        strength += 25  # å¼ºåŠ¿å¸‚åœº
        final_prob *= 1.2  # æ¦‚ç‡ä¸Šæµ®20%
    elif sentiment_score > 60:
        strength += 15
        final_prob *= 1.1
    elif sentiment_score < 40:
        strength -= 10  # å¼±åŠ¿å¸‚åœºæ‰£åˆ†
        final_prob *= 0.9
    
    # ã€æ–°å¢ã€‘ç›¸å¯¹å¼ºåº¦åŠ æˆ
    if features.get('relative_strength', 0) > 3.0:  # è·‘èµ¢å¸‚åœº3å€
        strength += 20
    
    # ã€æ–°å¢ã€‘èµ„é‡‘+æ¿å—å…±æŒ¯
    if (features.get('net_buy_amount', 0) > 100000000 and  # 1äº¿ä¸ªè‚¡èµ„é‡‘
        features.get('is_hot_sector', False)):              # çƒ­é—¨æ¿å—
        strength += 30  # å¼ºåŠ¿å…±æŒ¯
    
    return {
        'strength_score': min(strength, 150),  # ä¸Šé™æé«˜åˆ°150
        # ... å…¶ä»–è¿”å›å€¼ ...
    }
```

### Phase 4: å®šæ—¶ä»»åŠ¡ï¼ˆ1å¤©ï¼‰

#### 4.1 æ¯æ—¥æ•°æ®æ›´æ–°
```python
# scripts/update_market_sentiment.py

import asyncio
from datetime import datetime
from stockainews.crawlers.tonghuashun.hot_sectors import TonghuashunHotSectorsCrawler
from stockainews.crawlers.legulegu.market_activity import LeguLeguMarketActivityCrawler
from stockainews.services.market_sentiment_service import MarketSentimentService

async def update_daily_sentiment():
    """æ¯æ—¥æ›´æ–°å¸‚åœºæƒ…ç»ªæ•°æ®"""
    print(f"[{datetime.now()}] å¼€å§‹æ›´æ–°å¸‚åœºæƒ…ç»ªæ•°æ®...")
    
    # 1. çˆ¬å–çƒ­é—¨æ¿å—
    sector_crawler = TonghuashunHotSectorsCrawler()
    sectors = await sector_crawler.crawl_hot_sectors()
    
    # 2. çˆ¬å–èµšé’±æ•ˆåº”
    activity_crawler = LeguLeguMarketActivityCrawler()
    market_data = activity_crawler.crawl_market_activity()
    
    # 3. ä¿å­˜åˆ°æ•°æ®åº“
    service = MarketSentimentService()
    service.save_hot_sectors(sectors)
    service.save_market_sentiment(market_data)
    
    print(f"[{datetime.now()}] å¸‚åœºæƒ…ç»ªæ•°æ®æ›´æ–°å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(update_daily_sentiment())
```

#### 4.2 Windows ä»»åŠ¡è®¡åˆ’
```bash
# æ¯å¤©15:30æ‰§è¡Œï¼ˆæ”¶ç›˜åï¼‰
python scripts/update_market_sentiment.py
```

---

## æ•ˆæœé¢„ä¼°

### å¯¹ 002202 çš„æ”¹è¿›æ•ˆæœ

| ç»´åº¦ | åŸæ¨¡å‹ | å¢åŠ æƒ…ç»ªæ•°æ®å | æå‡ |
|------|--------|----------------|------|
| **æ¿å—åŠ æˆ** | 0åˆ† | +30åˆ†ï¼ˆçƒ­é—¨æ¿å—ï¼‰ + 30åˆ†ï¼ˆèµ„é‡‘å…±æŒ¯ï¼‰ | +60åˆ† |
| **å¸‚åœºæƒ…ç»ª** | 0åˆ† | +25åˆ†ï¼ˆå¼ºåŠ¿å¸‚åœºï¼Œæƒ…ç»ª75åˆ†ï¼‰ | +25åˆ† |
| **ç›¸å¯¹å¼ºåº¦** | 0åˆ† | +20åˆ†ï¼ˆæ¶¨å¹…10% vs å¸‚åœº0.68%ï¼‰ | +20åˆ† |
| **å¼ºåº¦åˆ†** | 55åˆ† | 160åˆ†ï¼ˆä¸Šé™150ï¼‰ | +95åˆ† |
| **æ¦‚ç‡è°ƒæ•´** | æ—  | Ã—1.2ï¼ˆå¼ºåŠ¿å¸‚åœºåŠ æˆï¼‰ | +20% |
| **æœ€ç»ˆæ¦‚ç‡** | 0.40 | 0.40 Ã— 1.2 + æ¿å—æ•ˆåº” â‰ˆ **0.70+** | **+75%** |

### é¢„æœŸæ”¹è¿›ç›®æ ‡
- **å‡†ç¡®ç‡**ï¼šä»å½“å‰ 40-50% æå‡è‡³ 65-75%
- **å¬å›ç‡**ï¼šå‡å°‘æ¼æŠ¥ï¼ˆåƒ002202è¿™ç§å¤§è¡Œæƒ…ï¼‰ä» 50% é™è‡³ 20%
- **AUC**ï¼šä» 0.65-0.70 æå‡è‡³ 0.80+

---

## å®æ–½è®¡åˆ’

| é˜¶æ®µ | ä»»åŠ¡ | å·¥ä½œé‡ | ä¼˜å…ˆçº§ |
|------|------|--------|--------|
| **Phase 1** | åŒèŠ±é¡ºçƒ­é—¨æ¿å—çˆ¬è™« | 1å¤© | ğŸ”´ æœ€é«˜ |
| **Phase 1** | ä¹å’•ä¹è‚¡èµšé’±æ•ˆåº”çˆ¬è™« | 1å¤© | ğŸ”´ æœ€é«˜ |
| **Phase 2** | æ•°æ®å­˜å‚¨ä¸æœåŠ¡ | 1å¤© | ğŸŸ  é«˜ |
| **Phase 3** | ç‰¹å¾é›†æˆåˆ°æ¨¡å‹ | 2å¤© | ğŸŸ  é«˜ |
| **Phase 4** | å®šæ—¶ä»»åŠ¡ä¸æµ‹è¯• | 1å¤© | ğŸŸ¡ ä¸­ |

**æ€»å·¥ä½œé‡**ï¼šçº¦ **5-6å¤©**

---

## é£é™©ä¸æ³¨æ„äº‹é¡¹

### 1. çˆ¬è™«ç¨³å®šæ€§
- **é£é™©**ï¼šç½‘ç«™æ”¹ç‰ˆã€åçˆ¬è™«
- **åº”å¯¹**ï¼š
  - ä½¿ç”¨Playwrightæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
  - æ·»åŠ User-Agentå’Œä»£ç†
  - å¤±è´¥é‡è¯•æœºåˆ¶
  - å¤‡ç”¨æ•°æ®æº

### 2. æ•°æ®æ—¶æ•ˆæ€§
- **é—®é¢˜**ï¼šä¹å’•ä¹è‚¡æ•°æ®æ›´æ–°é¢‘ç‡ï¼ˆå¯èƒ½ä¸æ˜¯å®æ—¶ï¼‰
- **åº”å¯¹**ï¼š
  - ä¼˜å…ˆä½¿ç”¨ç›˜ä¸­æ•°æ®ï¼ˆå¦‚å¯è·å–ï¼‰
  - ç¼“å­˜å†å²æ•°æ®ä½œä¸ºå¤‡ç”¨

### 3. ç‰¹å¾è¿‡æ‹Ÿåˆ
- **é£é™©**ï¼šå¢åŠ å¤ªå¤šç‰¹å¾å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ
- **åº”å¯¹**ï¼š
  - ä½¿ç”¨äº¤å‰éªŒè¯
  - ç‰¹å¾é‡è¦æ€§åˆ†æ
  - å®šæœŸå›æµ‹

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³å¼€å§‹ï¼ˆå»ºè®®ï¼‰
1. âœ… **ç¡®è®¤æ•°æ®æºå¯è®¿é—®æ€§**ï¼šæµ‹è¯•ä¸¤ä¸ªç½‘ç«™æ˜¯å¦èƒ½æ­£å¸¸çˆ¬å–
2. ğŸ”„ **å®ç°åŸºç¡€çˆ¬è™«**ï¼šå…ˆå®ç°ä¸€ä¸ªç®€å•ç‰ˆæœ¬ï¼ŒéªŒè¯æ•°æ®è´¨é‡
3. ğŸ“Š **æ•ˆæœè¯„ä¼°**ï¼šç”¨å†å²æ•°æ®å›æµ‹ï¼ŒéªŒè¯æ”¹è¿›æ•ˆæœ

### éœ€è¦ç”¨æˆ·ç¡®è®¤
- â“ æ˜¯å¦ç«‹å³å¼€å§‹å®æ–½ï¼Ÿ
- â“ æ˜¯å¦éœ€è¦å¸®ä½ å®ç°çˆ¬è™«ä»£ç ï¼Ÿ
- â“ æ˜¯å¦éœ€è¦å…ˆåšå°è§„æ¨¡æµ‹è¯•ï¼Ÿ

---

**æ€»ç»“**ï¼šä½ çš„å»ºè®®éå¸¸å…³é”®ï¼è¿™ä¸¤ä¸ªæ•°æ®æºå°†æ˜¾è‘—æå‡æ¨¡å‹å¯¹"çƒ­ç‚¹é©±åŠ¨å‹"å’Œ"æƒ…ç»ªé©±åŠ¨å‹"è¡Œæƒ…çš„è¯†åˆ«èƒ½åŠ›ï¼Œé¢„è®¡å‡†ç¡®ç‡æå‡ **50%ä»¥ä¸Š**ã€‚

